{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-20 22:56:37.643463: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734728197.659941   38782 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734728197.664928   38782 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-20 22:56:37.680956: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/media/mohamed/AC6030326030059C/CMP1Materials/Forth/First/NLP/Project/dataset/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Attention, Input, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import sys\n",
    "sys.path.append('pizza/utils')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'tf_bert_model_2' (type TFBertModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for attention_mask.\n\nCall arguments received by layer 'tf_bert_model_2' (type TFBertModel):\n  • input_ids=<KerasTensor shape=(None, 30), dtype=int32, sparse=False, name=input_ids>\n  • attention_mask=<KerasTensor shape=(None, 30), dtype=int32, sparse=False, name=attention_mask_pizza>\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 94\u001b[0m\n\u001b[1;32m     91\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m BertTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     92\u001b[0m bert_model \u001b[38;5;241m=\u001b[39m TFBertModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 94\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_encoder_decoder_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbert_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_labels_pizza\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m21\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mnum_labels_drinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m21\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[7], line 17\u001b[0m, in \u001b[0;36mcreate_encoder_decoder_model\u001b[0;34m(bert_model, hidden_dim, num_labels_pizza, num_labels_drinks, max_length)\u001b[0m\n\u001b[1;32m     15\u001b[0m     layer\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# BERT output\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m bert_output \u001b[38;5;241m=\u001b[39m \u001b[43mbert_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask_pizza\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m bert_embeddings \u001b[38;5;241m=\u001b[39m bert_output\u001b[38;5;241m.\u001b[39mlast_hidden_state  \u001b[38;5;66;03m# Shape: (batch_size, seq_len, hidden_dim)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Add Bidirectional LSTM layers\u001b[39;00m\n",
      "File \u001b[0;32m/media/mohamed/AC6030326030059C/CMP1Materials/Forth/First/NLP/Project/dataset/venv/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/media/mohamed/AC6030326030059C/CMP1Materials/Forth/First/NLP/Project/dataset/venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:436\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m--> 436\u001b[0m unpacked_inputs \u001b[38;5;241m=\u001b[39m \u001b[43minput_processing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args_and_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munpacked_inputs)\n",
      "File \u001b[0;32m/media/mohamed/AC6030326030059C/CMP1Materials/Forth/First/NLP/Project/dataset/venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:513\u001b[0m, in \u001b[0;36minput_processing\u001b[0;34m(func, config, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m         output[k] \u001b[38;5;241m=\u001b[39m v\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 513\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(v)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not allowed only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mallowed_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is accepted for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(main_input, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(main_input):\n\u001b[1;32m    517\u001b[0m         \u001b[38;5;66;03m# EagerTensors don't allow to use the .name property so we check for a real Tensor\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'tf_bert_model_2' (type TFBertModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for attention_mask.\n\nCall arguments received by layer 'tf_bert_model_2' (type TFBertModel):\n  • input_ids=<KerasTensor shape=(None, 30), dtype=int32, sparse=False, name=input_ids>\n  • attention_mask=<KerasTensor shape=(None, 30), dtype=int32, sparse=False, name=attention_mask_pizza>\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_encoder_decoder_model(bert_model, hidden_dim, num_labels_pizza, num_labels_drinks, max_length):\n",
    "    # Define BERT input layers\n",
    "    input_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name=\"input_ids\")\n",
    "    attention_mask_pizza = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name=\"attention_mask_pizza\")\n",
    "    attention_mask_drinks = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name=\"attention_mask_drinks\")\n",
    "\n",
    "    for layer in bert_model.layers:\n",
    "        layer.trainable = False\n",
    "    # BERT output\n",
    "    bert_output = bert_model(input_ids=input_ids, attention_mask=attention_mask_pizza)\n",
    "    bert_embeddings = bert_output.last_hidden_state  # Shape: (batch_size, seq_len, hidden_dim)\n",
    "\n",
    "    # Add Bidirectional LSTM layers\n",
    "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(hidden_dim, return_sequences=True))(bert_embeddings)\n",
    "    x = tf.keras.layers.LSTM(hidden_dim, return_sequences=True)(x)\n",
    "\n",
    "    # Add dropout and regularization to decoder LSTM\n",
    "    decoder_lstm = tf.keras.layers.LSTM(256, return_sequences=True,\n",
    "                       dropout=0.2, recurrent_dropout=0.2,\n",
    "                       kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                       name=\"Decoder_LSTM\")\n",
    "    decoder_outputs = decoder_lstm(x)\n",
    "\n",
    "    # Project both tensors to the same dimension (256)\n",
    "    x_projected = tf.keras.layers.Dense(256)(x)\n",
    "    attention_pizza = tf.keras.layers.Attention(name=\"Attention_Layer_Pizza\")([decoder_outputs, x_projected])\n",
    "    attention_drinks = tf.keras.layers.Attention(name=\"Attention_Layer_Drinks\")([decoder_outputs, x_projected])\n",
    "    \n",
    "    # Add dropout after attention\n",
    "    attention_pizza = tf.keras.layers.Dropout(0.2)(attention_pizza)\n",
    "    attention_drinks = tf.keras.layers.Dropout(0.2)(attention_drinks)\n",
    "\n",
    "    combined_pizza = tf.keras.layers.Concatenate()([decoder_outputs, attention_pizza])\n",
    "    combined_drinks = tf.keras.layers.Concatenate()([decoder_outputs, attention_drinks])\n",
    "\n",
    "    # Add batch normalization and dropout before final layers\n",
    "    combined_pizza = tf.keras.layers.BatchNormalization()(combined_pizza)\n",
    "    combined_pizza = tf.keras.layers.Dropout(0.2)(combined_pizza)\n",
    "    combined_drinks = tf.keras.layers.BatchNormalization()(combined_drinks)\n",
    "    combined_drinks = tf.keras.layers.Dropout(0.2)(combined_drinks)\n",
    "\n",
    "    # Pizza Output\n",
    "    pizza_output = tf.keras.layers.TimeDistributed(\n",
    "        tf.keras.layers.Dense(num_labels_pizza, \n",
    "                              activation=\"softmax\", \n",
    "                              kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        name=\"Pizza_Output_Layer\"\n",
    "    )(combined_pizza)\n",
    "\n",
    "    # Drinks Output\n",
    "    drinks_output = tf.keras.layers.TimeDistributed(\n",
    "        tf.keras.layers.Dense(num_labels_drinks, \n",
    "                              activation=\"softmax\", \n",
    "                              kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        name=\"Drinks_Output_Layer\"\n",
    "    )(combined_drinks)\n",
    "\n",
    "    # Define the model with two outputs\n",
    "    model = tf.keras.Model(inputs=[input_ids, attention_mask_pizza, attention_mask_drinks], outputs=[pizza_output, drinks_output], name=\"Hybrid_Encoder_Decoder_NER\")\n",
    "\n",
    "    return model\n",
    "\n",
    "    \n",
    "    \n",
    "vocab_size = 30522  # this is the size of the BERT tokenizer\n",
    "embedding_dim = 128\n",
    "hidden_dim = 64\n",
    "num_labels = 33\n",
    "max_len=30 # max length of the input sequences is 25\n",
    "\n",
    "\n",
    "# entities=np.load('full_negate_entities.npy', allow_pickle=True)\n",
    "# entities_id = {e.item(): i+1 for i, e in enumerate(entities)}\n",
    "# entities_id['0']=0\n",
    "# entities_id['O']=0\n",
    "\n",
    "# reversed_entities_id = {v: k for k, v in entities_id.items() if k != 0}\n",
    "# reversed_entities_id[0]='O'\n",
    "\n",
    "# print(entities_id)\n",
    "# print(reversed_entities_id)\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "model = create_encoder_decoder_model(bert_model, hidden_dim, num_labels_pizza=21,num_labels_drinks=21, max_length=max_len)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/mohamed/AC6030326030059C/CMP1Materials/Forth/First/NLP/Project/dataset/venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "I0000 00:00:1734728203.916194   38782 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1649 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Hybrid_Encoder_Decoder_NER\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Hybrid_Encoder_Decoder_NER\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Input_Sequence      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Embedding_Layer     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,906,816</span> │ Input_Sequence[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Embedding_Layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gaussian_noise      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Bidirectional_LSTM  │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ gaussian_noise[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Bidirectional_LS… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Bidirectional_LS… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Bidirectional_LS… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Bidirectional_LS… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Decoder_LSTM (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ Bidirectional_LS… │\n",
       "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Attention_Layer     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Decoder_LSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ Bidirectional_LS… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Attention_Layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Decoder_LSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Pizza_Output_Layer  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">10,773</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Drinks_Output_Layer │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">10,773</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Input_Sequence      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Embedding_Layer     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │  \u001b[38;5;34m3,906,816\u001b[0m │ Input_Sequence[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ Embedding_Layer[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gaussian_noise      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mGaussianNoise\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Bidirectional_LSTM  │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m), │    \u001b[38;5;34m263,168\u001b[0m │ gaussian_noise[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ Bidirectional_LS… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Bidirectional_LS… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ Bidirectional_LS… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Bidirectional_LS… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Decoder_LSTM (\u001b[38;5;33mLSTM\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m525,312\u001b[0m │ Bidirectional_LS… │\n",
       "│                     │                   │            │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Attention_Layer     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ Decoder_LSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ Bidirectional_LS… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ Attention_Layer[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ Decoder_LSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │      \u001b[38;5;34m2,048\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Pizza_Output_Layer  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m21\u001b[0m)    │     \u001b[38;5;34m10,773\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Drinks_Output_Layer │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m21\u001b[0m)    │     \u001b[38;5;34m10,773\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,718,890</span> (18.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,718,890\u001b[0m (18.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,717,866</span> (18.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,717,866\u001b[0m (18.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> (4.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,024\u001b[0m (4.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def intialize_model(VOCAB_SIZE, EMBEDDING_DIM, MAX_LEN, NUM_CLASSES_PIZZA, NUM_CLASSES_DRINKS):\n",
    "    input_seq = tf.keras.layers.Input(shape=(MAX_LEN,), dtype='int32', name=\"Input_Sequence\")\n",
    "\n",
    "    # Add dropout to embedding layer\n",
    "    embedding = tf.keras.layers.Embedding(input_dim=VOCAB_SIZE, output_dim=EMBEDDING_DIM, input_length=MAX_LEN, name=\"Embedding_Layer\")(input_seq)\n",
    "    embedding = tf.keras.layers.Dropout(0.2)(embedding)\n",
    "    \n",
    "    # Add Gaussian noise layer\n",
    "    noisy_embedding = tf.keras.layers.GaussianNoise(0.1)(embedding)\n",
    "\n",
    "    # Add recurrent dropout to LSTM\n",
    "    encoder_outputs, forward_h, forward_c, backward_h, backward_c = tf.keras.layers.Bidirectional(\n",
    "        tf.keras.layers.LSTM(128, return_sequences=True, return_state=True, \n",
    "             dropout=0.2, recurrent_dropout=0.2,\n",
    "             kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "             name=\"Encoder_LSTM\"),\n",
    "        name=\"Bidirectional_LSTM\"\n",
    "    )(noisy_embedding)  # Using noisy embedding instead of regular embedding\n",
    "\n",
    "    state_h = tf.keras.layers.Concatenate()([forward_h, backward_h])\n",
    "    state_c = tf.keras.layers.Concatenate()([forward_c, backward_c])\n",
    "\n",
    "    # Rest of the model remains the same\n",
    "    decoder_lstm = tf.keras.layers.LSTM(256, return_sequences=True,\n",
    "                       dropout=0.2, recurrent_dropout=0.2,\n",
    "                       kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                       name=\"Decoder_LSTM\")\n",
    "    decoder_outputs = decoder_lstm(encoder_outputs, initial_state=[state_h, state_c])\n",
    "\n",
    "    attention = tf.keras.layers.Attention(name=\"Attention_Layer\")([decoder_outputs, encoder_outputs])\n",
    "    attention = tf.keras.layers.Dropout(0.2)(attention)\n",
    "\n",
    "    combined = tf.keras.layers.Concatenate()([decoder_outputs, attention])\n",
    "    combined = tf.keras.layers.BatchNormalization()(combined)\n",
    "    combined = tf.keras.layers.Dropout(0.2)(combined)\n",
    "\n",
    "    pizza_output = tf.keras.layers.TimeDistributed(\n",
    "        tf.keras.layers.Dense(NUM_CLASSES_PIZZA, \n",
    "                              activation=\"softmax\", \n",
    "                              kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        name=\"Pizza_Output_Layer\"\n",
    "    )(combined)\n",
    "\n",
    "    drinks_output = tf.keras.layers.TimeDistributed(\n",
    "        tf.keras.layers.Dense(NUM_CLASSES_DRINKS, \n",
    "                              activation=\"softmax\", \n",
    "                              kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        name=\"Drinks_Output_Layer\"\n",
    "    )(combined)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input_seq, outputs=[pizza_output, drinks_output], name=\"Hybrid_Encoder_Decoder_NER\")\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, clipnorm=1.0),\n",
    "                  loss={\n",
    "                      \"Pizza_Output_Layer\": \"sparse_categorical_crossentropy\",\n",
    "                      \"Drinks_Output_Layer\": \"sparse_categorical_crossentropy\"\n",
    "                  },\n",
    "                  metrics={\n",
    "                      \"Pizza_Output_Layer\": \"accuracy\",\n",
    "                      \"Drinks_Output_Layer\": \"accuracy\"\n",
    "                  })\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "VOCAB_SIZE = 30522\n",
    "EMBEDDING_DIM = 128  \n",
    "MAX_LEN = 30\n",
    "NUM_CLASSES_PIZZA = 21\n",
    "NUM_CLASSES_DRINKS = 21\n",
    "\n",
    "model= intialize_model(VOCAB_SIZE, EMBEDDING_DIM, MAX_LEN, NUM_CLASSES_PIZZA,NUM_CLASSES_DRINKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/mohamed/AC6030326030059C/CMP1Materials/Forth/First/NLP/Project/dataset/venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 34 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "# model1 = load_model('../models/shared_encoder_decoder02_noise.keras')\n",
    "\n",
    "model.load_weights('../checkpoints/model_noise_06-0.28.weights.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Encoder_Decoder_NER\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Encoder_Decoder_NER\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Input_Sequence      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Embedding_Layer     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,906,816</span> │ Input_Sequence[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Embedding_Layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Bidirectional_LSTM  │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Bidirectional_LS… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Bidirectional_LS… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Bidirectional_LS… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Bidirectional_LS… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Decoder_LSTM (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ Bidirectional_LS… │\n",
       "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Attention_Layer     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Decoder_LSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ Bidirectional_LS… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Attention_Layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Decoder_LSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Order_Output_Layer  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,565</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Input_Sequence      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Embedding_Layer     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │  \u001b[38;5;34m3,906,816\u001b[0m │ Input_Sequence[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ Embedding_Layer[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Bidirectional_LSTM  │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m), │    \u001b[38;5;34m263,168\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ Bidirectional_LS… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Bidirectional_LS… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ Bidirectional_LS… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Bidirectional_LS… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Decoder_LSTM (\u001b[38;5;33mLSTM\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m525,312\u001b[0m │ Bidirectional_LS… │\n",
       "│                     │                   │            │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Attention_Layer     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ Decoder_LSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ Bidirectional_LS… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ Attention_Layer[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ Decoder_LSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │      \u001b[38;5;34m2,048\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Order_Output_Layer  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m5\u001b[0m)     │      \u001b[38;5;34m2,565\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,097,681</span> (53.78 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,097,681\u001b[0m (53.78 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,698,885</span> (17.92 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,698,885\u001b[0m (17.92 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> (4.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,024\u001b[0m (4.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,397,772</span> (35.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m9,397,772\u001b[0m (35.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2 = load_model('../models/shared_encoder_decoder2.keras')\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_pizza_test = np.load('../data/processed/test/input_ids_pizza_test.npy')\n",
    "\n",
    "padded_labels_pizza_test = np.load('../data/processed/test/padded_labels_pizza_test.npy')\n",
    "padded_labels_drink_test = np.load('../data/processed/test/padded_labels_drink_test.npy')\n",
    "\n",
    "# attention_masks_drink_test=np.load('data/processed/test/attention_masks_drink_test.npy', allow_pickle=True)\n",
    "# attention_masks_pizza_test=np.load('data/processed/test/attention_masks_pizza_test.npy', allow_pickle=True)\n",
    "\n",
    "padded_labels_test_second = np.load('../data/processed/test/padded_labels_test_second.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_test_sentences = np.load(\n",
    "    '../data/processed/test/processed_test_sentences.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = {\"input_ids\": input_ids_pizza_test, \"attention_mask_pizza\": attention_masks_pizza_test, \"attention_mask_drinks\": attention_masks_drink_test}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions1 = np.array(model.predict(input_ids_pizza_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions2 = np.array(model2.predict(input_ids_pizza_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1357, 30, 21)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-SIZE' 'I-SIZE' 'B-VOLUME' 'I-VOLUME' 'B-NOT_DRINKTYPE'\n",
      " 'I-NOT_DRINKTYPE' 'B-NOT_NUMBER' 'I-NOT_NUMBER' 'B-NOT_CONTAINERTYPE'\n",
      " 'I-NOT_CONTAINERTYPE' 'B-CONTAINERTYPE' 'I-CONTAINERTYPE' 'B-NOT_VOLUME'\n",
      " 'I-NOT_VOLUME' 'B-NUMBER' 'I-NUMBER' 'B-DRINKTYPE' 'I-DRINKTYPE'\n",
      " 'B-NOT_SIZE' 'I-NOT_SIZE']\n",
      "['B-SIZE' 'I-SIZE' 'B-NOT_STYLE' 'I-NOT_STYLE' 'B-STYLE' 'I-STYLE'\n",
      " 'B-NOT_NUMBER' 'I-NOT_NUMBER' 'B-QUANTITY' 'I-QUANTITY' 'B-NOT_TOPPING'\n",
      " 'I-NOT_TOPPING' 'B-NUMBER' 'I-NUMBER' 'B-TOPPING' 'I-TOPPING'\n",
      " 'B-NOT_QUANTITY' 'I-NOT_QUANTITY' 'B-NOT_SIZE' 'I-NOT_SIZE']\n",
      "['B-PIZZAORDER' 'I-PIZZAORDER' 'B-DRINKORDER' 'I-DRINKORDER']\n"
     ]
    }
   ],
   "source": [
    "entity_labels_drink=np.load('../data/processed/entity_labels_drink.npy')\n",
    "entity_labels_pizza=np.load('../data/processed/entity_labels_pizza.npy')\n",
    "enitity_labels_second=np.load('../data/processed/entity_labels_second.npy')\n",
    "\n",
    "print(entity_labels_drink)\n",
    "print(entity_labels_pizza)\n",
    "print(enitity_labels_second)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'B-SIZE',\n",
       " 2: 'I-SIZE',\n",
       " 3: 'B-VOLUME',\n",
       " 4: 'I-VOLUME',\n",
       " 5: 'B-NOT_DRINKTYPE',\n",
       " 6: 'I-NOT_DRINKTYPE',\n",
       " 7: 'B-NOT_NUMBER',\n",
       " 8: 'I-NOT_NUMBER',\n",
       " 9: 'B-NOT_CONTAINERTYPE',\n",
       " 10: 'I-NOT_CONTAINERTYPE',\n",
       " 11: 'B-CONTAINERTYPE',\n",
       " 12: 'I-CONTAINERTYPE',\n",
       " 13: 'B-NOT_VOLUME',\n",
       " 14: 'I-NOT_VOLUME',\n",
       " 15: 'B-NUMBER',\n",
       " 16: 'I-NUMBER',\n",
       " 17: 'B-DRINKTYPE',\n",
       " 18: 'I-DRINKTYPE',\n",
       " 19: 'B-NOT_SIZE',\n",
       " 20: 'I-NOT_SIZE',\n",
       " 0: 'O'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_id_drink = {i+1: str(e) for i, e in enumerate(entity_labels_drink)}\n",
    "entities_id_drink[0] = 'O'\n",
    "entities_id_drink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'B-SIZE',\n",
       " 2: 'I-SIZE',\n",
       " 3: 'B-NOT_STYLE',\n",
       " 4: 'I-NOT_STYLE',\n",
       " 5: 'B-STYLE',\n",
       " 6: 'I-STYLE',\n",
       " 7: 'B-NOT_NUMBER',\n",
       " 8: 'I-NOT_NUMBER',\n",
       " 9: 'B-QUANTITY',\n",
       " 10: 'I-QUANTITY',\n",
       " 11: 'B-NOT_TOPPING',\n",
       " 12: 'I-NOT_TOPPING',\n",
       " 13: 'B-NUMBER',\n",
       " 14: 'I-NUMBER',\n",
       " 15: 'B-TOPPING',\n",
       " 16: 'I-TOPPING',\n",
       " 17: 'B-NOT_QUANTITY',\n",
       " 18: 'I-NOT_QUANTITY',\n",
       " 19: 'B-NOT_SIZE',\n",
       " 20: 'I-NOT_SIZE',\n",
       " 0: 'O'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_id_pizza = {i+1: str(e) for i, e in enumerate(entity_labels_pizza)}\n",
    "entities_id_pizza[0] = 'O'\n",
    "entities_id_pizza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'B-PIZZAORDER',\n",
       " 2: 'I-PIZZAORDER',\n",
       " 3: 'B-DRINKORDER',\n",
       " 4: 'I-DRINKORDER',\n",
       " 0: 'O'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enitities_id_second = {i+1: str(e) for i, e in enumerate(enitity_labels_second)}\n",
    "enitities_id_second[0] = 'O'\n",
    "enitities_id_second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_entities1(processed_sentences, predictions, entities_id):\n",
    "    pred_entities = []\n",
    "    for i in range(predictions.shape[0]):\n",
    "        sen=[entities_id[np.argmax(predictions[i][j])] for j in range(predictions.shape[1])]\n",
    "        pred_entities.append(sen[1:len(processed_sentences[i].split())+1])\n",
    "    return pred_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1357, 30, 5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_pizza = np.array(get_prediction_entities1(\n",
    "    processed_test_sentences, predictions1[0], entities_id_pizza), dtype=object)\n",
    "entities_drink = np.array(get_prediction_entities1(\n",
    "    processed_test_sentences, predictions1[1], entities_id_drink), dtype=object)\n",
    "entities_second = np.array(get_prediction_entities1(processed_test_sentences,predictions2, enitities_id_second),dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-PIZZAORDER',\n",
       " 'I-PIZZAORDER',\n",
       " 'I-PIZZAORDER',\n",
       " 'I-PIZZAORDER',\n",
       " 'I-PIZZAORDER',\n",
       " 'I-PIZZAORDER',\n",
       " 'I-PIZZAORDER']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_second_entities(entities_second):\n",
    "    current_entity = 'O'\n",
    "    processed_entities = []\n",
    "    for entity in entities_second:\n",
    "        if entity =='O' and current_entity == 'O':\n",
    "            processed_entities.append('O')\n",
    "        elif entity == 'O' and current_entity != 'O':\n",
    "            if current_entity.startswith('B-'):\n",
    "                current_entity = 'I-'+current_entity[2:]\n",
    "            processed_entities.append(current_entity)\n",
    "        elif entity.startswith('I-') and current_entity == 'O':\n",
    "            current_entity = 'B-'+entity[2:]\n",
    "            processed_entities.append(current_entity)\n",
    "        else:\n",
    "            current_entity = entity   \n",
    "            processed_entities.append(current_entity) \n",
    "            \n",
    "    return processed_entities\n",
    "\n",
    "\n",
    "process_second_entities(entities_second[120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get me a small mushroom and sausage pizza with no pineapple\n",
      "['O', 'O', 'B-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER']\n",
      "['O', 'O', 'B-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER']\n"
     ]
    }
   ],
   "source": [
    "numb = 130\n",
    "\n",
    "print(processed_test_sentences[numb])\n",
    "print(entities_second[numb])\n",
    "print(process_second_entities(entities_second[numb]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_test_sentences[533].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entities_drink[533])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entities_pizza[533])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entities_second[533])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_JSON(words, predictions1, predictions2, predictions3):\n",
    "    words = words.split()\n",
    "    order = {\"ORDER\": {\"PIZZAORDER\": [], \"DRINKORDER\": []}}\n",
    "    current_pizza = None\n",
    "    current_drink = None\n",
    "\n",
    "    for i in range(len(words)):\n",
    "        if predictions1[i] == 'B-PIZZAORDER':\n",
    "            if current_pizza:\n",
    "                order[\"ORDER\"][\"PIZZAORDER\"].append(current_pizza)\n",
    "            current_pizza = {\"NUMBER\": None, \"SIZE\": None, \"STYLE\": None, \"AllTopping\": []}\n",
    "        elif predictions1[i] == 'B-DRINKORDER':\n",
    "            if current_drink:\n",
    "                order[\"ORDER\"][\"DRINKORDER\"].append(current_drink)\n",
    "            current_drink = {\"NUMBER\": None, \"SIZE\": None, \"DRINKTYPE\": None, \"CONTAINERTYPE\": None}\n",
    "\n",
    "        if predictions2[i].startswith('B-'):\n",
    "            tag = predictions2[i][2:]\n",
    "            if tag == 'NUMBER':\n",
    "                if current_pizza:\n",
    "                    current_pizza[\"NUMBER\"] = words[i]\n",
    "                elif current_drink:\n",
    "                    current_drink[\"NUMBER\"] = words[i]\n",
    "            elif tag == 'SIZE':\n",
    "                if current_pizza:\n",
    "                    current_pizza[\"SIZE\"] = words[i]\n",
    "                elif current_drink:\n",
    "                    current_drink[\"SIZE\"] = words[i]\n",
    "            elif tag == 'TOPPING':\n",
    "                current_pizza[\"AllTopping\"].append({\"NOT\": False, \"Quantity\": None, \"Topping\": words[i]})\n",
    "\n",
    "        if predictions3[i].startswith('B-'):\n",
    "            tag = predictions3[i][2:]\n",
    "            if tag == 'CONTAINERTYPE':\n",
    "                current_drink[\"CONTAINERTYPE\"] = words[i]\n",
    "            elif tag == 'DRINKTYPE':\n",
    "                current_drink[\"DRINKTYPE\"] = words[i]\n",
    "            elif tag == 'TOPPING':\n",
    "                current_pizza[\"AllTopping\"][-1][\"Topping\"] = words[i]\n",
    "\n",
    "    if current_pizza:\n",
    "        order[\"ORDER\"][\"PIZZAORDER\"].append(current_pizza)\n",
    "    if current_drink:\n",
    "        order[\"ORDER\"][\"DRINKORDER\"].append(current_drink)\n",
    "\n",
    "    return order\n",
    "\n",
    "# Example usage\n",
    "input_sentence = \"two large pizzas with ham and one bottle of diet coke and one small pizza with mushrooms\"\n",
    "model_1_prediction = ['B-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER', 'O', 'B-DRINKORDER', 'I-DRINKORDER',\n",
    "                      'I-DRINKORDER', 'I-DRINKORDER', 'I-DRINKORDER', 'O', 'B-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER']\n",
    "model_2_prediction = ['B-NUMBER', 'B-SIZE', 'O', 'O', 'B-TOPPING', 'O', 'B-NUMBER', 'O', 'O', 'O', 'O', 'O', 'B-NUMBER', 'B-SIZE', 'O', 'O', 'B-TOPPING']\n",
    "model_3_prediction = ['B-NUMBER', 'B-SIZE', 'O', 'O', 'O', 'O', 'B-NUMBER', 'B-CONTAINERTYPE',\n",
    "                      'O', 'B-DRINKTYPE', 'I-DRINKTYPE', 'O', 'B-NUMBER', 'B-SIZE', 'O', 'O', 'O']\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# formatted_order_json = json.dumps(get_JSON(\n",
    "#     input_sentence, model_1_prediction, model_2_prediction, model_3_prediction), indent=4)\n",
    "# print(formatted_order_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ORDER (PIZZAORDER (NUMBER two ) (SIZE large ) pizzas with (TOPPING ham ) ) and (DRINKORDER (NUMBER one ) (CONTAINERTYPE bottle ) of (DRINKTYPE diet ) coke ) and (PIZZAORDER (NUMBER one ) (SIZE small ) pizza with (TOPPING mushrooms ) ) )\n"
     ]
    }
   ],
   "source": [
    "input_sentence = \"two large pizzas with ham and one bottle of diet coke and one small pizza with mushrooms\"\n",
    "model_1_prediction = ['B-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER', 'O', 'B-DRINKORDER', 'I-DRINKORDER',\n",
    "                      'I-DRINKORDER', 'I-DRINKORDER', 'I-DRINKORDER', 'O', 'B-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER']\n",
    "model_2_prediction = ['B-NUMBER', 'B-SIZE', 'O', 'O', 'B-TOPPING', 'O', 'B-NUMBER', 'O', 'O', 'O', 'O', 'O', 'B-NUMBER', 'B-SIZE', 'O', 'O', 'B-TOPPING']\n",
    "model_3_prediction = ['B-NUMBER', 'B-SIZE', 'O', 'O', 'O', 'O', 'B-NUMBER', 'B-CONTAINERTYPE',\n",
    "                      'O', 'B-DRINKTYPE', 'I-DRINKTYPE', 'O', 'B-NUMBER', 'B-SIZE', 'O', 'O', 'O']\n",
    "\n",
    "# \"(ORDER (PIZZAORDER (NUMBER two ) (SIZE large ) pizzas with (TOPPING ham ) ) and (DRINKORDER (NUMBER one ) (SIZE bottle ) of (DRINKTYPE diet coke ) ) and (PIZZAORDER (NUMBER one ) (SIZE small ) pizza with (TOPPING mushrooms ) ) )\"\n",
    "def format_to_TOP(input_sentence, model_1_prediction, model_2_prediction, model_3_prediction):\n",
    "    words = input_sentence.split()\n",
    "    result = \"(ORDER \"\n",
    "    i = 0\n",
    "    while i < len(words):\n",
    "        if model_1_prediction[i].startswith('B-'):\n",
    "            tag = model_1_prediction[i][2:]\n",
    "            result += f\"({tag} \"\n",
    "            while i < len(words) and (model_1_prediction[i].startswith('B-') or model_1_prediction[i].startswith('I-')):\n",
    "                if model_2_prediction[i].startswith('B-'):\n",
    "                    result += f\"({model_2_prediction[i][2:]} {words[i]} ) \"\n",
    "                elif model_3_prediction[i].startswith('B-'):\n",
    "                    result += f\"({model_3_prediction[i][2:]} {words[i]} ) \"\n",
    "                else:\n",
    "                    result += f\"{words[i]} \"\n",
    "                i += 1\n",
    "                if i < len(words) and model_1_prediction[i] == 'O':\n",
    "                    break\n",
    "            result = result.rstrip() + \" ) \"\n",
    "        else:\n",
    "            result += f\"{words[i]} \"\n",
    "            i += 1\n",
    "    result = result.rstrip() + \" )\"\n",
    "    return result\n",
    "\n",
    "formatted_TOP = format_to_TOP(input_sentence, model_1_prediction, model_2_prediction, model_3_prediction)\n",
    "print(formatted_TOP)\n",
    "\n",
    "\"(ORDER i want (PIZZAORDER (NUMBER a ) pizza with (TOPPING pesto ) and (TOPPING mushrooms ) but no (NOT (TOPPING pineapple ) ) ) )\"\n",
    "\n",
    "input_sentence = \"i want a pizza with pesto and mushrooms but no pineapple\"\n",
    "model_1_prediction = ['O', 'O', 'B-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER' ]\n",
    "model_2_prediction = ['O','O','B-NUMBER','O','B-TOPPING','O','B-TOPPING','O','O','O','B-NOT_TOPPING']\n",
    "# model_3_prediction = ['O','O','O','O','B-TOPPING','O','B-TOPPING','O','O','O','B-NOT_TOPPING']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(ORDER get me two pepsis a coke and (NUMBER (NUMBER five ) (SIZE large ) ) fantas )'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_to_TOP(processed_test_sentences[3], entities_pizza[3], entities_drink[3], entities_second[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(ORDER i want (PIZZAORDER (NUMBER a ) pizza with (TOPPING pesto ) and (TOPPING mushrooms ) but no pineapple ) )'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_TOP(words, predictions1, predictions2, predictions3):\n",
    "    words=words.split()\n",
    "    \n",
    "    result = \"(ORDER \"\n",
    "    i = 0\n",
    "    not_flag = False\n",
    "    c = min(len(words), len(predictions1), len(\n",
    "        predictions2), len(predictions3))\n",
    "    while i < c:\n",
    "        if i < c and predictions3[i].startswith('B-'):\n",
    "            tag = predictions3[i][2:]\n",
    "            result += f\"({tag} \"\n",
    "            while i < c and (predictions3[i].startswith('B-') or predictions3[i].startswith('I-')):\n",
    "                if predictions1[i].startswith('B-'):\n",
    "                    if(predictions1[i].startswith('B-NOT_')):\n",
    "                        result += f\"(NOT ({predictions1[i][6:]} {words[i]} ) \"\n",
    "                        not_flag = True\n",
    "                    else:\n",
    "                        result += f\"({predictions1[i][2:]} {words[i]} ) \"\n",
    "                elif predictions2[i].startswith('B-'):\n",
    "                    # Handle multi-word drink types\n",
    "                    if i+1 < c and predictions2[i+1].startswith('I-'):\n",
    "                        result += f\"({predictions2[i][2:]} {words[i]} {words[i+1]} ) \"\n",
    "                        i += 1\n",
    "                    else:\n",
    "                        result += f\"({predictions2[i][2:]} {words[i]} ) \"\n",
    "                else:\n",
    "                    result += f\"{words[i]} \"\n",
    "                i += 1\n",
    "                if i < c and predictions3[i] == 'O':\n",
    "                    break\n",
    "            if not_flag:\n",
    "                result = result.rstrip() + \" ) ) \"\n",
    "                not_flag = False\n",
    "            else:\n",
    "                result = result.rstrip() + \" ) \"\n",
    "        else:\n",
    "            result += f\"{words[i]} \"\n",
    "            i += 1\n",
    "    result = result.rstrip() + \" )\"\n",
    "    return result\n",
    "\n",
    "\n",
    "get_TOP(processed_test_sentences[0], entities_pizza[0],\n",
    "        entities_drink[0], entities_second[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'B-NUMBER', 'B-STYLE', 'O', 'B-QUANTITY', 'I-QUANTITY', 'B-TOPPING', 'O', 'O', 'B-QUANTITY', 'B-TOPPING', 'O', 'O', 'O']\n",
      "i would like to try two medium tuna pizzas with extra cheese and no pesto\n"
     ]
    }
   ],
   "source": [
    "print(entities_pizza[1])\n",
    "print(processed_test_sentences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "print(len(processed_test_sentences[0].split()))\n",
    "print(len(entities_pizza[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "533\n",
      "634\n",
      "713\n",
      "753\n",
      "950\n",
      "973\n",
      "1019\n",
      "1034\n",
      "1135\n",
      "1169\n",
      "1174\n",
      "1262\n",
      "1269\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(processed_test_sentences)):\n",
    "    lp=len(processed_test_sentences[i].split())\n",
    "    p=len(entities_pizza[i])\n",
    "    d=len(entities_drink[i])\n",
    "    s=len(entities_second[i])\n",
    "    if lp!=p or lp!=d or lp!=s:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'O', 'B-NUMBER', 'O', 'O', 'O', 'O', 'O', 'O', 'O']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_drink[114]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'O',\n",
       " 'B-PIZZAORDER',\n",
       " 'I-PIZZAORDER',\n",
       " 'I-PIZZAORDER',\n",
       " 'I-PIZZAORDER',\n",
       " 'I-PIZZAORDER',\n",
       " 'I-PIZZAORDER',\n",
       " 'I-PIZZAORDER',\n",
       " 'I-PIZZAORDER']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_second_entities(entities_second[114])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_entities_second = [process_second_entities(es) for es in entities_second]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(processed_entities_second)):\n",
    "    if len(processed_entities_second[i])!=len(entities_second[i]):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1357"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_entities_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tops = [get_TOP(processed_test_sentences[i], entities_pizza[i], entities_drink[i], processed_entities_second[i]) for i in range(len(processed_test_sentences))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(ORDER i (PIZZAORDER would like to have (NUMBER one ) pie along with (TOPPING ham ) and (TOPPING olives ) without pepperoni ) )'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tops[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import extract_text, load_data, apply_negation, get_entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PATH = '../data/raw/PIZZA_test.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, explanations_test, topics_test, decoupled_topics_test = map(np.array, zip(\n",
    "    *[extract_text(data, 'test') for data in load_data(TEST_PATH, 'test')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('../data/output/topics_test.npy', topics_test)\n",
    "np.save('../data/output/tops_noise.npy', tops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'entity_resolution'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mentity_resolution\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PizzaSkillEntityResolver\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msemantic_matchers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_unordered_exact_match, is_semantics_only_unordered_exact_match, \\\n\u001b[0;32m      3\u001b[0m     is_semantics_only_unordered_exact_match_post_ER, is_unordered_exact_match_post_ER, is_semantics_only_unordered_exact_match_post_ER_top_top\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrees\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TopSemanticTree, ExpressSemanticTree\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'entity_resolution'"
     ]
    }
   ],
   "source": [
    "from entity_resolution import PizzaSkillEntityResolver\n",
    "from semantic_matchers import is_unordered_exact_match, is_semantics_only_unordered_exact_match, \\\n",
    "    is_semantics_only_unordered_exact_match_post_ER, is_unordered_exact_match_post_ER, is_semantics_only_unordered_exact_match_post_ER_top_top\n",
    "from trees import TopSemanticTree, ExpressSemanticTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
