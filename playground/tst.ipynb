{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SIZE' 'NOT_STYLE' 'STYLE' 'NOT_NUMBER' 'QUANTITY' 'NOT_TOPPING' 'NUMBER'\n",
      " 'TOPPING' 'NOT_QUANTITY' 'NOT_SIZE']\n"
     ]
    }
   ],
   "source": [
    "l=np.load('data/processed/final_negated_entities_pizza.npy')\n",
    "\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=np.load('processed_sentences_no_conct.npy', allow_pickle=True)\n",
    "entities=np.load('entities_to_words_not_processed.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['can', 'i', 'have', 'a', 'large', 'bbq', 'pulled', 'pork']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0].tolist().split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('text_2d.npy',np.array([t.tolist().split(' ') for t in text], dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=np.load('text_2d.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(i) for i in t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TOPPING': 1, 'VOLUME': 2, 'NOT_TOPPING': 3, 'DRINKTYPE': 4, 'NOT_STYLE': 5, 'NUMBER': 6, 'QUANTITY': 7, 'CONTAINERTYPE': 8, 'SIZE': 9, 'STYLE': 10, '0': 0, 'O': 0}\n"
     ]
    }
   ],
   "source": [
    "entities=np.load('negated_entities.npy', allow_pickle=True)\n",
    "entities_id = {e.item(): i+1 for i, e in enumerate(entities)}\n",
    "entities_id['0']=0\n",
    "entities_id['O']=0\n",
    "\n",
    "print(entities_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2456446"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=np.load(\"tokens_to_entities.npy\", allow_pickle=True)\n",
    "len(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('can', 'O'), ('i', 'O'), ('have', 'O'), ('a', 'NUMBER'), ('large', 'SIZE'), ('bb', 'TOPPING'), ('##q', 'TOPPING'), ('pulled', 'TOPPING'), ('pork', 'TOPPING')]\n"
     ]
    }
   ],
   "source": [
    "print(l[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/mohamed/AC6030326030059C/CMP1Materials/Forth/First/NLP/Project/dataset/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2064"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(l[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_train=np.load('data/processed/train/input_ids_pizza_train.npy', allow_pickle=True)\n",
    "padded_labels_drink_train=np.load('data/processed/train/padded_labels_drink_train.npy', allow_pickle=True)\n",
    "padded_labels_pizza_train=np.load('data/processed/train/padded_labels_pizza_train.npy', allow_pickle=True)\n",
    "input_ids_dev=np.load('data/processed/dev/input_ids_drink_dev.npy', allow_pickle=True)\n",
    "padded_labels_drink_dev=np.load('data/processed/dev/padded_labels_drink_dev.npy', allow_pickle=True)\n",
    "padded_labels_pizza_dev=np.load('data/processed/dev/padded_labels_pizza_dev.npy', allow_pickle=True)\n",
    "\n",
    "# Check for NaNs\n",
    "assert not np.isnan(input_ids_train).any(), \"Input contains NaNs!\"\n",
    "assert not np.isnan(padded_labels_pizza_train).any(), \"Pizza labels contain NaNs!\"\n",
    "assert not np.isnan(padded_labels_drink_train).any(), \"Drink labels contain NaNs!\"\n",
    "\n",
    "# Check input and output ranges\n",
    "assert np.max(input_ids_train) < 30522, \"Input IDs exceed vocabulary size!\"\n",
    "assert np.min(input_ids_train) >= 0, \"Input IDs contain negative values!\"\n",
    "assert np.max(padded_labels_pizza_train) < 21, \"Pizza labels exceed class size!\"\n",
    "assert np.max(padded_labels_drink_train) < 21, \"Drink labels exceed class size!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>let me prefer a extra large sauteed spinach an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>could you give me a exta large pizza with roas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>can you handle this order a pizza make it etra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>let me try 5 lnch pizzas with garlic onions an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>i need you to order me a pie in med size along...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              order\n",
       "0   0  let me prefer a extra large sauteed spinach an...\n",
       "1   1  could you give me a exta large pizza with roas...\n",
       "2   2  can you handle this order a pizza make it etra...\n",
       "3   3  let me try 5 lnch pizzas with garlic onions an...\n",
       "4   4  i need you to order me a pie in med size along..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('test_set.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count                                                  4000\n",
       "unique                                                 4000\n",
       "top       get me one large onion and pineapple pie with ...\n",
       "freq                                                      1\n",
       "Name: order, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_long_orders = df['order'].apply(lambda x: len(x.split()) > 30).sum()\n",
    "print(num_long_orders)\n",
    "\n",
    "df['order'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "36/4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "\n",
    "# Label maps for the models\n",
    "MODEL_1_LABEL_MAP = {\n",
    "    \"B-PIZZAORDER\": 1,\n",
    "    \"I-PIZZAORDER\": 2,\n",
    "    \"B-DRINKORDER\": 3,\n",
    "    \"I-DRINKORDER\": 4,\n",
    "    \"O\": 5\n",
    "}\n",
    "\n",
    "MODEL_2_LABEL_MAP = {\n",
    "    'B-DRINKTYPE': 1, 'I-DRINKTYPE': 2,\n",
    "    'B-SIZE': 3, 'I-SIZE': 4,\n",
    "    'B-NUMBER': 5, 'I-NUMBER': 6,\n",
    "    'B-CONTAINERTYPE': 7, 'I-CONTAINERTYPE': 8,\n",
    "    'B-COMPLEX_TOPPING': 9, 'I-COMPLEX_TOPPING': 10,\n",
    "    'B-TOPPING': 11, 'I-TOPPING': 12,\n",
    "    'B-NEG_TOPPING': 13, 'I-NEG_TOPPING': 14,\n",
    "    'B-NEG_STYLE': 15, 'I-NEG_STYLE': 16,\n",
    "    'B-STYLE': 17, 'I-STYLE': 18,\n",
    "    'B-QUANTITY': 19, 'I-QUANTITY': 20,\n",
    "    'O': 21\n",
    "}\n",
    "\n",
    "# Function to apply both models and get the TOP_DECOUPLED format\n",
    "\n",
    "\n",
    "def process_entry(entry):\n",
    "    src_text = entry[\"train.SRC\"]\n",
    "    true_top = entry[\"train.TOP\"]\n",
    "\n",
    "    # Tokenize and preprocess the input text\n",
    "    tokens = tokenize_input(src_text)\n",
    "    # Convert tokens to integers\n",
    "    tokens = tokens_to_ints(tokens, vocab)\n",
    "    # Convert to tensor\n",
    "    tokens = torch.tensor(tokens).unsqueeze(0).to(device)\n",
    "\n",
    "    # Get predictions from the first model\n",
    "    model_1_output = model_1(tokens)\n",
    "    first_model_labels = model_1_output.argmax(\n",
    "        dim=-1).squeeze(0).tolist()  # Ensure list of labels\n",
    "\n",
    "    # Get predictions from the second model\n",
    "    model_2_output = model_2(tokens)\n",
    "    second_model_labels = model_2_output.argmax(\n",
    "        dim=-1).squeeze(0).tolist()  # Ensure list of labels\n",
    "\n",
    "    # Generate TOP_DECOUPLED output\n",
    "    top_decoupled = generate_top_decoupled(\n",
    "        src_text, first_model_labels, second_model_labels)\n",
    "\n",
    "    # Preprocess TOP to JSON format\n",
    "    predicted_json = preprocess_top(top_decoupled)\n",
    "    true_json = preprocess_true_top(true_top)\n",
    "\n",
    "    with open(\"predicted_true.json\", \"a\") as f:\n",
    "        f.write(f\"tokens: {tokens}\\n\")\n",
    "        f.write(f\"true: {true_top}\\n\")\n",
    "    write_comparison_file(predicted_json, true_json, top_decoupled)\n",
    "\n",
    "    # Compare the predicted JSON with the ground truth JSON\n",
    "    return predicted_json == true_json\n",
    "\n",
    "\n",
    "def generate_top_decoupled(text, first_labels, second_labels):\n",
    "    words = text.split()\n",
    "    first_labels = first_labels[:len(words)]\n",
    "    second_labels = second_labels[:len(words)]\n",
    "\n",
    "    # Debugging output\n",
    "    with open(\"predicted_true.json\", \"a\") as f:\n",
    "        f.write(str(words) + \"\\n\")\n",
    "        f.write(str([next(k for k, v in MODEL_1_LABEL_MAP.items() if v == l)\n",
    "                for l in first_labels]) + \"\\n\")\n",
    "        f.write(str([next(k for k, v in MODEL_2_LABEL_MAP.items() if v == l)\n",
    "                for l in second_labels]) + \"\\n\\n\")\n",
    "\n",
    "    result = [\"(ORDER\"]\n",
    "    current_order_type = None\n",
    "    current_group = None\n",
    "    open_groups = []  # To keep track of open groups for proper closing\n",
    "\n",
    "    for i, (word, first_label, second_label) in enumerate(zip(words, first_labels, second_labels)):\n",
    "        first_label_key = next(\n",
    "            (key for key, value in MODEL_1_LABEL_MAP.items()\n",
    "             if value == first_label), None\n",
    "        )\n",
    "        # Handle the first labels (ORDER type: PIZZAORDER, DRINKORDER)\n",
    "        if first_label in [MODEL_1_LABEL_MAP[\"B-PIZZAORDER\"], MODEL_1_LABEL_MAP[\"B-DRINKORDER\"]]:\n",
    "            if current_order_type is not None:\n",
    "                result.append(\")\")  # Close the previous order\n",
    "                open_groups.pop()  # Remove from open_groups stack\n",
    "            current_order_type = \"PIZZAORDER\" if first_label == MODEL_1_LABEL_MAP[\n",
    "                \"B-PIZZAORDER\"] else \"DRINKORDER\"\n",
    "            result.append(f\"({current_order_type}\")\n",
    "            open_groups.append(current_order_type)\n",
    "\n",
    "        # if the first label is I- and the current order type is None, consider it as B- and add the order type\n",
    "        # and do the same if it's an I- but for a different order type\n",
    "        elif first_label_key.startswith(\"I-\") and (current_order_type is None or current_order_type != first_label_key[2:]):\n",
    "            if current_order_type is not None:\n",
    "                result.append(\")\")  # Close the previous order\n",
    "                open_groups.pop()\n",
    "            current_order_type = \"PIZZAORDER\" if first_label == MODEL_1_LABEL_MAP[\n",
    "                \"I-PIZZAORDER\"] else \"DRINKORDER\"\n",
    "            result.append(f\"({current_order_type}\")\n",
    "            open_groups.append(current_order_type)\n",
    "\n",
    "        elif first_label == MODEL_1_LABEL_MAP[\"O\"] and current_order_type is not None:\n",
    "            result.append(\")\")  # Close the current order\n",
    "            open_groups.pop()\n",
    "            current_order_type = None\n",
    "\n",
    "        elif first_label == MODEL_1_LABEL_MAP[\"O\"] and current_order_type is None:\n",
    "            continue  # Skip the word if it's not part of an order\n",
    "\n",
    "        # Handle the second labels (attributes like NUMBER, SIZE, TOPPING, etc.)\n",
    "        if second_label != MODEL_2_LABEL_MAP[\"O\"]:\n",
    "            second_label_key = next(\n",
    "                (key for key, value in MODEL_2_LABEL_MAP.items()\n",
    "                 if value == second_label), None\n",
    "            )\n",
    "            if not second_label_key:\n",
    "                print(\n",
    "                    f\"Warning: Unexpected label {second_label} encountered for word '{word}'. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            label_type = second_label_key.split(\"-\")[-1]\n",
    "            if label_type not in [\"NEG_TOPPING\", \"NEG_STYLE\"]:\n",
    "                if second_label_key.startswith(\"B-\"):\n",
    "                    # Close the previous group if there is one\n",
    "                    if current_group:\n",
    "                        result.append(\")\")  # Close the previous group\n",
    "                        # since this is positive, if the current top group is a not group close it as well\n",
    "                        if current_group[\"type\"] == \"NEG_TOPPING\" or current_group[\"type\"] == \"NEG_STYLE\":\n",
    "                            result.append(\")\")\n",
    "                            open_groups.pop()\n",
    "                        open_groups.pop()\n",
    "                    current_group = {\"type\": label_type, \"content\": [word]}\n",
    "                    result.append(f\"({label_type} {word}\")\n",
    "                    open_groups.append(label_type)\n",
    "\n",
    "                elif second_label_key.startswith(\"I-\") and current_group and current_group[\"type\"] == label_type:\n",
    "                    current_group[\"content\"].append(word)\n",
    "                    result[-1] += f\" {word}\"  # Append to the last open group\n",
    "\n",
    "                elif second_label_key.startswith(\"I-\") and (not current_group or current_group[\"type\"] != label_type):\n",
    "                    print(\n",
    "                        f\"Warning: I- tag '{label_type}' for word '{word}' without preceding B- tag. Converting to B-.\")\n",
    "                    # Close the previous group if there is one\n",
    "                    if current_group:\n",
    "                        result.append(\")\")  # Close the previous group\n",
    "                        # since this is positive, if the current top group is a not group close it as well\n",
    "                        if current_group[\"type\"] == \"NEG_TOPPING\" or current_group[\"type\"] == \"NEG_STYLE\":\n",
    "                            result.append(\")\")\n",
    "                            open_groups.pop()\n",
    "                        open_groups.pop()\n",
    "                    current_group = {\"type\": label_type, \"content\": [word]}\n",
    "                    result.append(f\"({label_type} {word}\")\n",
    "                    open_groups.append(label_type)\n",
    "\n",
    "            # Special handling for NEG_TOPPING and NEG_STYLE\n",
    "            else:\n",
    "                if second_label_key.startswith(\"B-\"):\n",
    "                    if current_group:\n",
    "                        result.append(\")\")\n",
    "                        open_groups.pop()\n",
    "                    result.append(\n",
    "                        f\"(NOT ({'TOPPING' if label_type == 'NEG_TOPPING' else 'STYLE'} {word}\")\n",
    "                    current_group = {\"type\": label_type, \"content\": [word]}\n",
    "                    open_groups.append(label_type)\n",
    "                    open_groups.append(\"NOT\")\n",
    "                elif second_label_key.startswith(\"I-\") and current_group and current_group[\"type\"] == label_type:\n",
    "                    current_group[\"content\"].append(word)\n",
    "                    result[-1] += f\" {word}\"  # Append to the last open group\n",
    "                elif second_label_key.startswith(\"I-\") and (not current_group or current_group[\"type\"] != label_type):\n",
    "                    # Close the previous group if there is one\n",
    "                    if current_group:\n",
    "                        result.append(\")\")\n",
    "                        open_groups.pop()\n",
    "                    print(\n",
    "                        f\"Warning: I- tag '{label_type}' for word '{word}' without preceding B- tag. Converting to B-.\")\n",
    "                    result.append(\n",
    "                        f\"(NOT ({'TOPPING' if label_type == 'NEG_TOPPING' else 'STYLE'} {word}\")\n",
    "                    current_group = {\"type\": label_type, \"content\": [word]}\n",
    "                    open_groups.append(\"NOT\")\n",
    "                    open_groups.append(label_type)\n",
    "        # Handle O labels\n",
    "        else:\n",
    "            if current_group:\n",
    "                result.append(\")\")  # Close the current group\n",
    "                open_groups.pop()\n",
    "            current_group = None\n",
    "\n",
    "    # Close any remaining open groups\n",
    "    while open_groups:\n",
    "        result.append(\")\")\n",
    "        open_groups.pop()\n",
    "\n",
    "    result.append(\")\")  # Close the overall ORDER group\n",
    "    return \" \".join(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
