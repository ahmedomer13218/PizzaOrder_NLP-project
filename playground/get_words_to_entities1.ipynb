{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2456446\n"
     ]
    }
   ],
   "source": [
    "data_train = []\n",
    "with open('PIZZA_train.json', 'r') as f:\n",
    "    for line in f:\n",
    "        data_train.append(json.loads(line))\n",
    "\n",
    "print(len(data_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348\n"
     ]
    }
   ],
   "source": [
    "with open('PIZZA_dev.json', 'r') as file:\n",
    "    data_dev = json.load(file)\n",
    "\n",
    "# Print the loaded data\n",
    "print(len(data_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=np.load('processed_sentences_no_conct_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_train(data):\n",
    "    return data['train.SRC'], data['train.EXR'], data['train.TOP'], data['train.TOP-DECOUPLED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_dev(data):\n",
    "    return data['dev.SRC'], data['dev.EXR'], data['dev.TOP'], data['dev.PCFG_ERR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, explanations_dev, topics_dev, decoupled_topics_dev = map(\n",
    "    np.array, zip(*map(extract_text_dev, data_dev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, explanations_train, topics_train, decoupled_topics_train = map(\n",
    "    np.array, zip(*map(extract_text_train, data_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_dev = set([word[1:]\n",
    "               for t in topics_dev for word in t.split() if word.isupper()])\n",
    "\n",
    "entities_train = set([word[1:]\n",
    "               for t in topics_train for word in t.split() if word.isupper()])\n",
    "\n",
    "full_entities = entities_dev | entities_train\n",
    "\n",
    "enitities_exclude_not = full_entities - {'NOT'}\n",
    "\n",
    "negate_mapping = {}\n",
    "for entity in full_entities:\n",
    "    if entity != 'NOT':\n",
    "        negate_mapping[entity] = \"NOT_\" + entity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SIZE': 'NOT_SIZE',\n",
       " 'QUANTITY': 'NOT_QUANTITY',\n",
       " 'ORDER': 'NOT_ORDER',\n",
       " 'VOLUME': 'NOT_VOLUME',\n",
       " 'CONTAINERTYPE': 'NOT_CONTAINERTYPE',\n",
       " 'COMPLEX_TOPPING': 'NOT_COMPLEX_TOPPING',\n",
       " 'STYLE': 'NOT_STYLE',\n",
       " 'DRINKORDER': 'NOT_DRINKORDER',\n",
       " 'DRINKTYPE': 'NOT_DRINKTYPE',\n",
       " 'NUMBER': 'NOT_NUMBER',\n",
       " 'TOPPING': 'NOT_TOPPING',\n",
       " 'PIZZAORDER': 'NOT_PIZZAORDER'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negate_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negate_topic(topic):\n",
    "    not_array = topic.split('NOT')\n",
    "    not_array = not_array[1:]\n",
    "    final_array = []\n",
    "    for element in not_array:\n",
    "        element = element.strip()\n",
    "        open_brackets = 1\n",
    "        result = \"\"\n",
    "        index = 0\n",
    "        while open_brackets > 0:\n",
    "            if element[index] == '(':\n",
    "                open_brackets += 1\n",
    "            elif element[index] == ')':\n",
    "                open_brackets -= 1\n",
    "            if open_brackets > 0:\n",
    "                result += element[index]\n",
    "            index += 1\n",
    "\n",
    "        final_array.append(result.strip())\n",
    "    return final_array\n",
    "\n",
    "\n",
    "def apply_negation(topic):\n",
    "    array = negate_topic(topic)\n",
    "    for el in array:\n",
    "        original_el = el\n",
    "        for entity in enitities_exclude_not:\n",
    "            el = el.replace(entity, negate_mapping[entity])\n",
    "            \n",
    "        topic = topic.replace(original_el, el)\n",
    "    return topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "negated_topics_train = np.vectorize(apply_negation)(topics_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "negated_topics_dev = np.vectorize(apply_negation)(topics_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SIZE', 'DRINKTYPE', 'QUANTITY', 'NUMBER', 'VOLUME', 'CONTAINERTYPE', 'TOPPING', 'STYLE'}\n"
     ]
    }
   ],
   "source": [
    "final_entities = full_entities.copy()\n",
    "final_entities.remove('NOT')\n",
    "final_entities.remove('COMPLEX_TOPPING')\n",
    "final_entities.remove('PIZZAORDER')\n",
    "final_entities.remove('DRINKORDER')\n",
    "final_entities.remove('ORDER')\n",
    "print(final_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SIZE': 'NOT_SIZE', 'DRINKTYPE': 'NOT_DRINKTYPE', 'QUANTITY': 'NOT_QUANTITY', 'NUMBER': 'NOT_NUMBER', 'VOLUME': 'NOT_VOLUME', 'CONTAINERTYPE': 'NOT_CONTAINERTYPE', 'TOPPING': 'NOT_TOPPING', 'STYLE': 'NOT_STYLE'}\n"
     ]
    }
   ],
   "source": [
    "negate_mapping = {}\n",
    "for entity in final_entities:\n",
    "    if entity != 'NOT':        negate_mapping[entity] = \"NOT_\" + entity\n",
    "\n",
    "print(negate_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_negated_entities = final_entities | set(negate_mapping.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "print(len(final_negated_entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"final_negated_entites.npy\",np.array(list(final_negated_entities)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "party - size pizza with banana peppers and peperonni and with yellow peppers\n",
      "(ORDER (PIZZAORDER (SIZE party - size ) pizza with (TOPPING banana peppers ) and (TOPPING peperonni ) and with (TOPPING yellow peppers ) ) )\n",
      "['B-SIZE', 'I-SIZE', 'I-SIZE', 'O', 'O', 'B-TOPPING', 'I-TOPPING', 'O', 'B-TOPPING', 'O', 'O', 'B-TOPPING', 'I-TOPPING']\n"
     ]
    }
   ],
   "source": [
    "def get_entity(topic,mapping):\n",
    "    # print(mapping)\n",
    "    words_array=topic.split()\n",
    "    result=[]\n",
    "    current_entity='O'\n",
    "    first=False\n",
    "    for word in words_array:\n",
    "        if word.startswith(\"(\"):\n",
    "            if word[1:] in mapping:\n",
    "                current_entity=word[1:]\n",
    "                first=True\n",
    "            else:\n",
    "                current_entity='O'\n",
    "        elif word.startswith(\")\"):\n",
    "            current_entity='O'\n",
    "        else:\n",
    "            if current_entity=='O':\n",
    "                result.append(current_entity)\n",
    "            else:\n",
    "                if first:\n",
    "                    result.append('B-'+current_entity)\n",
    "                    first=False\n",
    "                else:\n",
    "                    result.append('I-'+current_entity)    \n",
    "    return result\n",
    "        \n",
    "\n",
    "number=1205\n",
    "print(s[number])\n",
    "print(negated_topics_train[number])\n",
    "mp=get_entity(negated_topics_train[number],final_negated_entities)\n",
    "print(mp)\n",
    "# print(tokens[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   0%|          | 0/2456446 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2456446/2456446 [00:27<00:00, 87885.63it/s] \n",
      "dev: 100%|██████████| 348/348 [00:00<00:00, 103000.34it/s]\n"
     ]
    }
   ],
   "source": [
    "words_to_entities_train = [get_entity(topic, final_negated_entities) for topic in \n",
    "                           tqdm(negated_topics_train,desc=\"train\")]\n",
    "words_to_entities_dev = [get_entity(topic, final_negated_entities) for topic in \n",
    "                            tqdm(negated_topics_dev,desc=\"dev\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ORDER my order today is for (PIZZAORDER (NUMBER a ) (SIZE medium ) pizza i like the (STYLE thin crust ) and i will try the (TOPPING tuna ) but no (NOT (NOT_TOPPING pineapple ) ) ) thanks a lot )\n",
      "['O', 'O', 'O', 'O', 'O', 'B-NUMBER', 'B-SIZE', 'O', 'O', 'O', 'O', 'B-STYLE', 'I-STYLE', 'O', 'O', 'O', 'O', 'O', 'B-TOPPING', 'O', 'O', 'B-NOT_TOPPING', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "number=205\n",
    "print(negated_topics_dev[number])\n",
    "print(words_to_entities_dev[number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"words_to_entities_train.npy\", np.array(words_to_entities_train,dtype=object))\n",
    "np.save(\"words_to_entities_dev.npy\", np.array(words_to_entities_dev,dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
