{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2456446\n"
     ]
    }
   ],
   "source": [
    "data_train = []\n",
    "with open('PIZZA_train.json', 'r') as f:\n",
    "    for line in f:\n",
    "        data_train.append(json.loads(line))\n",
    "\n",
    "print(len(data_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348\n"
     ]
    }
   ],
   "source": [
    "with open('PIZZA_dev.json', 'r') as file:\n",
    "    data_dev = json.load(file)\n",
    "\n",
    "# Print the loaded data\n",
    "print(len(data_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357\n"
     ]
    }
   ],
   "source": [
    "data_test = []\n",
    "with open('PIZZA_test.json', 'r') as f:\n",
    "    for line in f:\n",
    "        data_test.append(json.loads(line))\n",
    "\n",
    "print(len(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=np.load('processed_sentences_no_conct_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_train(data):\n",
    "    return data['train.SRC'], data['train.EXR'], data['train.TOP'], data['train.TOP-DECOUPLED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_dev(data):\n",
    "    return data['dev.SRC'], data['dev.EXR'], data['dev.TOP'], data['dev.PCFG_ERR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_test(data):\n",
    "    return data['test.SRC'], data['test.EXR'], data['test.TOP'], data['test.PCFG_ERR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, explanations_dev, topics_dev, decoupled_topics_dev = map(\n",
    "    np.array, zip(*map(extract_text_dev, data_dev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, explanations_train, topics_train, decoupled_topics_train = map(\n",
    "    np.array, zip(*map(extract_text_train, data_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, explanations_test, topics_test, decoupled_topics_test = map(\n",
    "    np.array, zip(*map(extract_text_test, data_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_dev = set([word[1:]\n",
    "               for t in topics_dev for word in t.split() if word.isupper()])\n",
    "\n",
    "entities_train = set([word[1:]\n",
    "               for t in topics_train for word in t.split() if word.isupper()])\n",
    "\n",
    "entities_test = set([word[1:]\n",
    "               for t in topics_test for word in t.split() if word.isupper()])\n",
    "\n",
    "full_entities = entities_dev | entities_train | entities_test\n",
    "\n",
    "enitities_exclude_not = full_entities - {'NOT'}\n",
    "\n",
    "negate_mapping = {}\n",
    "for entity in full_entities:\n",
    "    if entity != 'NOT':\n",
    "        negate_mapping[entity] = \"NOT_\" + entity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negate_topic(topic):\n",
    "    not_array = topic.split('NOT')\n",
    "    not_array = not_array[1:]\n",
    "    final_array = []\n",
    "    for element in not_array:\n",
    "        element = element.strip()\n",
    "        open_brackets = 1\n",
    "        result = \"\"\n",
    "        index = 0\n",
    "        while open_brackets > 0:\n",
    "            if element[index] == '(':\n",
    "                open_brackets += 1\n",
    "            elif element[index] == ')':\n",
    "                open_brackets -= 1\n",
    "            if open_brackets > 0:\n",
    "                result += element[index]\n",
    "            index += 1\n",
    "\n",
    "        final_array.append(result.strip())\n",
    "    return final_array\n",
    "\n",
    "\n",
    "def apply_negation(topic):\n",
    "    array = negate_topic(topic)\n",
    "    for el in array:\n",
    "        original_el = el\n",
    "        for entity in enitities_exclude_not:\n",
    "            el = el.replace(entity, negate_mapping[entity])\n",
    "            \n",
    "        topic = topic.replace(original_el, el)\n",
    "    return topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "negated_topics_train = np.vectorize(apply_negation)(topics_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "negated_topics_dev = np.vectorize(apply_negation)(topics_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "negated_topics_test = np.vectorize(apply_negation)(topics_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PIZZAORDER', 'DRINKORDER'}\n"
     ]
    }
   ],
   "source": [
    "final_entities = full_entities.copy()\n",
    "final_entities.remove('NOT')\n",
    "final_entities.remove('COMPLEX_TOPPING')\n",
    "final_entities.remove('ORDER')\n",
    "final_entities.remove('CONTAINERTYPE')\n",
    "final_entities.remove('TOPPING')\n",
    "final_entities.remove('SIZE')\n",
    "final_entities.remove('QUANTITY')\n",
    "final_entities.remove('NUMBER')\n",
    "final_entities.remove('VOLUME')\n",
    "final_entities.remove('DRINKTYPE')\n",
    "final_entities.remove('STYLE')\n",
    "\n",
    "\n",
    "print(final_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PIZZAORDER': 'NOT_PIZZAORDER', 'DRINKORDER': 'NOT_DRINKORDER'}\n"
     ]
    }
   ],
   "source": [
    "negate_mapping = {}\n",
    "for entity in final_entities:\n",
    "    if entity != 'NOT':        negate_mapping[entity] = \"NOT_\" + entity\n",
    "\n",
    "print(negate_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_negated_entities2 = final_entities | set(negate_mapping.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"final_negated_entites2.npy\",np.array(list(final_entities)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_negated_entities1 = np.load(\"final_negated_entites.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['QUANTITY', 'STYLE', 'SIZE', 'TOPPING', 'NOT_VOLUME',\n",
       "       'NOT_TOPPING', 'NOT_SIZE', 'NUMBER', 'NOT_STYLE', 'VOLUME',\n",
       "       'CONTAINERTYPE', 'NOT_CONTAINERTYPE', 'NOT_NUMBER',\n",
       "       'NOT_DRINKTYPE', 'DRINKTYPE', 'NOT_QUANTITY'], dtype='<U17')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_negated_entities1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DRINKORDER', 'PIZZAORDER'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DRINKORDER', 'NOT_DRINKORDER', 'NOT_PIZZAORDER', 'PIZZAORDER'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_negated_entities2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.str_('(ORDER can i get (PIZZAORDER (NUMBER one ) (SIZE small ) (TOPPING pepperoni ) and (TOPPING chicken ) pizza with no (NOT (NOT_TOPPING mushrooms ) ) ) )')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negated_topics_test[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ORDER get me (PIZZAORDER (NUMBER a ) (SIZE small ) (TOPPING chicken ) (TOPPING pesto ) (TOPPING tuna ) pie ) )\n",
      "['O', 'O', 'B-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER']\n"
     ]
    }
   ],
   "source": [
    "def get_entity(topic,mapping,mapping2):\n",
    "    words_array=topic.split()\n",
    "        \n",
    "\n",
    "    result=[]\n",
    "    current_entity='O'\n",
    "    first=False\n",
    "    open_brackets=0\n",
    "    for word in words_array:\n",
    "        if word.startswith(\"(\"):\n",
    "            if word[1:] in mapping2:\n",
    "                open_brackets+=1\n",
    "            else:\n",
    "                if word[1:] in mapping:\n",
    "                    current_entity=word[1:]\n",
    "                    first=True\n",
    "                elif 'NOT' not in word[1:] and 'COMPLEX_TOPPING' not in word[1:]:\n",
    "                    current_entity='O'\n",
    "        elif word.startswith(\")\"):\n",
    "            if open_brackets>0:\n",
    "                open_brackets-=1\n",
    "            else:\n",
    "                current_entity='O'\n",
    "        else:\n",
    "            if current_entity=='O':\n",
    "                result.append(current_entity)\n",
    "            else:\n",
    "                if first:\n",
    "                    result.append('B-'+current_entity)\n",
    "                    first=False\n",
    "                else:\n",
    "                    result.append('I-'+current_entity)    \n",
    "    return result\n",
    "        \n",
    "\n",
    "\n",
    "number=150\n",
    "# print(s[number])\n",
    "print(negated_topics_test[number])\n",
    "mp=get_entity(negated_topics_test[number],final_entities,final_negated_entities1)\n",
    "print(mp)\n",
    "# print(tokens[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "4\n",
      "8\n",
      "11\n",
      "12\n",
      "14\n",
      "17\n",
      "18\n",
      "21\n",
      "22\n",
      "27\n",
      "30\n",
      "34\n",
      "36\n",
      "37\n",
      "39\n",
      "43\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "51\n",
      "55\n",
      "57\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "74\n",
      "75\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "86\n",
      "87\n",
      "88\n",
      "92\n",
      "94\n",
      "98\n",
      "101\n",
      "103\n",
      "106\n",
      "107\n",
      "109\n",
      "110\n",
      "111\n",
      "113\n",
      "114\n",
      "117\n",
      "121\n",
      "123\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "143\n",
      "145\n",
      "146\n",
      "147\n",
      "149\n",
      "156\n",
      "159\n",
      "161\n",
      "166\n",
      "168\n",
      "171\n",
      "173\n",
      "175\n",
      "176\n",
      "178\n",
      "179\n",
      "182\n",
      "190\n",
      "192\n",
      "194\n",
      "199\n",
      "200\n",
      "203\n",
      "205\n",
      "209\n",
      "211\n",
      "219\n",
      "221\n",
      "222\n",
      "224\n",
      "225\n",
      "229\n",
      "230\n",
      "233\n",
      "234\n",
      "242\n",
      "244\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "257\n",
      "258\n",
      "259\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "272\n",
      "273\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "282\n",
      "285\n",
      "286\n",
      "289\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "306\n",
      "307\n",
      "308\n",
      "310\n",
      "312\n",
      "313\n",
      "317\n",
      "318\n",
      "322\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "332\n",
      "333\n",
      "337\n",
      "340\n",
      "342\n",
      "344\n",
      "345\n",
      "346\n",
      "351\n",
      "353\n",
      "356\n",
      "357\n",
      "359\n",
      "362\n",
      "365\n",
      "369\n",
      "370\n",
      "373\n",
      "374\n",
      "375\n",
      "381\n",
      "382\n",
      "387\n",
      "388\n",
      "389\n",
      "392\n",
      "394\n",
      "395\n",
      "403\n",
      "404\n",
      "406\n",
      "407\n",
      "408\n",
      "411\n",
      "413\n",
      "426\n",
      "427\n",
      "429\n",
      "430\n",
      "431\n",
      "433\n",
      "435\n",
      "436\n",
      "438\n",
      "443\n",
      "444\n",
      "446\n",
      "447\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "455\n",
      "456\n",
      "458\n",
      "460\n",
      "463\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "480\n",
      "482\n",
      "483\n",
      "484\n",
      "487\n",
      "490\n",
      "495\n",
      "497\n",
      "502\n",
      "504\n",
      "506\n",
      "508\n",
      "510\n",
      "511\n",
      "513\n",
      "514\n",
      "515\n",
      "518\n",
      "519\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "530\n",
      "531\n",
      "532\n",
      "534\n",
      "535\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "562\n",
      "563\n",
      "564\n",
      "567\n",
      "573\n",
      "574\n",
      "575\n",
      "577\n",
      "578\n",
      "582\n",
      "585\n",
      "588\n",
      "591\n",
      "594\n",
      "596\n",
      "604\n",
      "605\n",
      "607\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "620\n",
      "622\n",
      "623\n",
      "624\n",
      "626\n",
      "637\n",
      "639\n",
      "643\n",
      "644\n",
      "645\n",
      "647\n",
      "648\n",
      "651\n",
      "652\n",
      "655\n",
      "656\n",
      "659\n",
      "660\n",
      "662\n",
      "665\n",
      "669\n",
      "671\n",
      "676\n",
      "678\n",
      "681\n",
      "682\n",
      "683\n",
      "688\n",
      "690\n",
      "691\n",
      "697\n",
      "700\n",
      "701\n",
      "702\n",
      "705\n",
      "710\n",
      "712\n",
      "713\n",
      "714\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "725\n",
      "727\n",
      "732\n",
      "736\n",
      "738\n",
      "739\n",
      "740\n",
      "743\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "753\n",
      "754\n",
      "756\n",
      "759\n",
      "761\n",
      "762\n",
      "763\n",
      "765\n",
      "768\n",
      "769\n",
      "772\n",
      "774\n",
      "775\n",
      "778\n",
      "782\n",
      "783\n",
      "785\n",
      "787\n",
      "788\n",
      "791\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "800\n",
      "802\n",
      "803\n",
      "805\n",
      "810\n",
      "815\n",
      "817\n",
      "818\n",
      "819\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "830\n",
      "831\n",
      "833\n",
      "834\n",
      "841\n",
      "843\n",
      "844\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "853\n",
      "855\n",
      "856\n",
      "858\n",
      "860\n",
      "863\n",
      "865\n",
      "867\n",
      "869\n",
      "870\n",
      "875\n",
      "877\n",
      "881\n",
      "883\n",
      "886\n",
      "888\n",
      "889\n",
      "892\n",
      "895\n",
      "901\n",
      "908\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "918\n",
      "919\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "928\n",
      "930\n",
      "931\n",
      "935\n",
      "936\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "944\n",
      "946\n",
      "948\n",
      "953\n",
      "955\n",
      "959\n",
      "960\n",
      "962\n",
      "963\n",
      "965\n",
      "967\n",
      "974\n",
      "977\n",
      "979\n",
      "981\n",
      "985\n",
      "986\n",
      "987\n",
      "990\n",
      "992\n",
      "1001\n",
      "1006\n",
      "1007\n",
      "1010\n",
      "1012\n",
      "1014\n",
      "1015\n",
      "1017\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1025\n",
      "1026\n",
      "1028\n",
      "1030\n",
      "1031\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1040\n",
      "1041\n",
      "1044\n",
      "1050\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1057\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1064\n",
      "1066\n",
      "1067\n",
      "1069\n",
      "1071\n",
      "1072\n",
      "1076\n",
      "1078\n",
      "1080\n",
      "1083\n",
      "1085\n",
      "1088\n",
      "1091\n",
      "1095\n",
      "1097\n",
      "1098\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1107\n",
      "1109\n",
      "1110\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1119\n",
      "1121\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1132\n",
      "1134\n",
      "1139\n",
      "1142\n",
      "1149\n",
      "1152\n",
      "1154\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1163\n",
      "1166\n",
      "1167\n",
      "1169\n",
      "1170\n",
      "1172\n",
      "1173\n",
      "1179\n",
      "1183\n",
      "1185\n",
      "1188\n",
      "1189\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1196\n",
      "1197\n",
      "1199\n",
      "1200\n",
      "1202\n",
      "1204\n",
      "1205\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1218\n",
      "1220\n",
      "1221\n",
      "1226\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1233\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1251\n",
      "1252\n",
      "1254\n",
      "1255\n",
      "1257\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1264\n",
      "1268\n",
      "1269\n",
      "1274\n",
      "1275\n",
      "1278\n",
      "1279\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1288\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1298\n",
      "1299\n",
      "1301\n",
      "1304\n",
      "1306\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1319\n",
      "1321\n",
      "1324\n",
      "1325\n",
      "1327\n",
      "1331\n",
      "1333\n",
      "1334\n",
      "1337\n",
      "1338\n",
      "1343\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1354\n"
     ]
    }
   ],
   "source": [
    "for i,sen in enumerate(negated_topics_test):\n",
    "    if \"(NOT\" in sen:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   0%|          | 0/2456446 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2456446/2456446 [01:25<00:00, 28838.25it/s]\n",
      "dev: 100%|██████████| 348/348 [00:00<00:00, 29543.33it/s]\n",
      "test: 100%|██████████| 1357/1357 [00:00<00:00, 29713.45it/s]\n"
     ]
    }
   ],
   "source": [
    "words_to_entities_train = [get_entity(topic, final_entities,final_negated_entities1) for topic in \n",
    "                           tqdm(negated_topics_train,desc=\"train\")]\n",
    "words_to_entities_dev = [get_entity(topic, final_entities,final_negated_entities1) for topic in \n",
    "                            tqdm(negated_topics_dev,desc=\"dev\")]\n",
    "words_to_entities_test = [get_entity(topic, final_entities,final_negated_entities1) for topic in\n",
    "                            tqdm(negated_topics_test,desc=\"test\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2456446\n",
      "348\n",
      "1357\n",
      "['O', 'O', 'O', 'B-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER', 'I-PIZZAORDER']\n"
     ]
    }
   ],
   "source": [
    "print(len(words_to_entities_train))\n",
    "print(len(words_to_entities_dev))\n",
    "print(len(words_to_entities_test))\n",
    "print(words_to_entities_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"words_to_entities_train2.npy\", np.array(words_to_entities_train,dtype=object))\n",
    "np.save(\"words_to_entities_dev2.npy\", np.array(words_to_entities_dev,dtype=object))\n",
    "np.save(\"words_to_entities_test2.npy\", np.array(words_to_entities_test,dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
